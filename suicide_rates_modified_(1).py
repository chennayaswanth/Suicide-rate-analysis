# -*- coding: utf-8 -*-
"""suicide_rates_modified (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YQJaCpHpT9nRNaPIqSjqV-11z7ZCEUrg
"""

import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn import preprocessing

""" Data Collection"""

df = pd.read_csv('/content/master1.csv')

df

df.shape

df.head()

# info of the parameters

df.info()

df = df.fillna(0)

""" Data Cleaning"""

# to check the number of null values in each parameter

df.isnull().sum()

#Replacing all the NaN values by the mean of that particular column

df['population']=df['population'].fillna(df['population'].mean())
df['suicides_no']=df['suicides_no'].fillna(df['suicides_no'].mean())
df['suicides/100k pop']=df['suicides/100k pop'].fillna(df['suicides/100k pop'].mean())

df['population']

# since we see that most of HDI(human development index) values are empty and we do not need the country-year column, we drop these columns.
#axis 1 is removes columns null values
#True:  -+ removing is done on the current DataFrame
df.drop(['country-year', 'HDI for year'], inplace=True, axis = 1)

# renaming some columns simply to make it easier to access them.

df = df.rename(columns={'gdp_per_capita ($)': 'gdp_per_capita', ' gdp_for_year ($) ':'gdp_for_year'})

# Possible age categories

df['age'].unique()

# Possible generations

df['generation'].unique()

#Cleaned dataset
df.head(10)

df.isnull().sum()

"""
Exploratory Data Analysis"""

# plot visualizing number of suicides wth respect to age-groups.

suicides_no_age = []

for a in df['age'].unique():
    suicides_no_age.append(sum(df[df['age'] == a]['suicides_no']))

plt.xticks(rotation=30)
sns.barplot(x = df['age'].unique(), y = suicides_no_age)

# plot of number_of suicides wrt year


suicides_no_year = []

for y in df['year'].unique():
    suicides_no_year.append(sum(df[df['year'] == y]['suicides_no']))

n_suicides_year = pd.DataFrame(suicides_no_year, columns=['suicides_no_year'])
n_suicides_year['year'] = df['year'].unique()

top_year = n_suicides_year.sort_values('suicides_no_year', ascending=False)['year']
top_suicides = n_suicides_year.sort_values('suicides_no_year', ascending=False)['suicides_no_year']

plt.figure(figsize=(8,5))
plt.xticks(rotation=90)
sns.barplot(x = top_year, y = top_suicides)

plt.figure(figsize=(10,3))
sns.barplot(x = 'suicides_no',
            y = 'sex',
            data = df)
plt.title('Gender - Suicide Count')
plt.show()

sns.countplot(data=df, x="generation", hue="sex")
plt.title('Generation hue Gender Counter')
plt.show()

plt.figure(figsize=(9,5))
sns.barplot(x = 'age',
            y = 'suicides_no',
            data = df,)
plt.title('Age - Suicide Count')
plt.show()

df['population']

df['population']=df['population']/df['population'].mean()

df['population']

df['population'].mean()

# Hypothesis testing
# Lets take H0 -> means are related , H1 -> means are not related

# Using linear regression for predicting suicude trend of male and female of all age groups belonging to the country Sweden.

data = pd.read_csv("master1.csv")
data = data[data['country'] == 'Sweden']

missing_val_count_by_column = (data.isnull().sum())
print(missing_val_count_by_column[missing_val_count_by_column > 0])
data = data.dropna(axis = 0)  # the lines having null values are deleted
data.head()

x = np.array(data.loc[:,'year']).reshape(-1,1)
y = np.array(data.loc[:,'suicides_no']).reshape(-1,1)
#Scatter Plot
plt.figure(figsize = [10,10])
plt.scatter(x=x,y=y,)
plt.xlabel('Year')
plt.ylabel('Suicides number')
plt.show()

""" Regression"""

#Linear Regression Models
from sklearn.linear_model import LinearRegression
reg = LinearRegression()
predict_space = np.linspace(min(x), max(x)).reshape(-1,1)  # Prediction Space

lis = ['female', 'male']
lis2 = ['5-14 years', '15-24 years', '25-34 years', '35-54 years', '55-74 years', '75+ years']
for i in lis:
    for k in lis2:
        data_1 = data[data['sex'] == i]
        data_sex = data_1[data_1['age'] == k ]
        x_sex = np.array(data_sex.loc[:,'year']).reshape(-1,1)
        y_sex = np.array(data_sex.loc[:,'suicides_no']).reshape(-1,1)
        reg.fit(x_sex,y_sex)                                               # Fit
        predicted = reg.predict(predict_space)                     # Prediction
        print( i, k, 'R^2 Score: ', reg.score(x_sex,y_sex))                       # R^2 calculation
        plt.plot(predict_space, predicted, color = 'black', linewidth = 2)
        plt.scatter(x_sex,y_sex)
        plt.title('Scatter Plot')
        plt.xlabel('Year')
        plt.ylabel('Suicides number')
        plt.show()

df['generation'].head(10)

df['population'].astype(int)

data={'year':df['year'],'population':df['population'].astype(int)}

df1=pd.DataFrame(data)
df1.head()

df['suicides_no']

Y = df.iloc[:, 4].values
Y=Y.astype(int)
Y

df1.population.max()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

data = pd.read_csv('master1.csv')

X = data.drop('suicides_no', axis=1)
y = data['suicides_no']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

import pandas as pd

# Assuming X_train is a pandas DataFrame
X_train = X_train.fillna(X_train.median())

df['suicides_no'] = df['suicides_no'].fillna(0)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt

data = pd.read_csv('master1.csv')


data.dropna(inplace=True)


data_encoded = pd.get_dummies(data)

X = data_encoded.drop('suicides_no', axis=1)
y = data_encoded['suicides_no']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = DecisionTreeClassifier(random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)